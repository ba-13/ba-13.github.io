---
layout: post
title: Balanced DCCA for Bird Vocalization Detection
excerpt-seperator: <!---->
tags:
  - project
  - machine-learning
---

I continued the SURGE few-shot-learning project by changing the problem statement.

<!---->

The PhD I mentioned before, remember? He asked me to join his problem statement of improving binary classification on a noisy dataset. Why do I keep getting such basic problems? I wanted a bit ingenuity, which was upcoming. Actually this was a multi (dual for us) modal dataset, where we had a microphone recording, and an accelerometer recording (consider as a better microphone) of 2 finch birds. 3 hours of the dataset was hand labelled, and using that we had to make better predictions on the remaining 11 hours of data. The accelerometer data gave an accuracy of 92%, but we only had to use the microphone for testing the rest 11 hours. So in some manner we had to make a model that improved the microphone dataset so it's output can be seen as a better representation for our detection task. In total, we were creating a better embedding of microphone data using accelerometer data only while training. I managed to code things out, and we submitted a paper with me being the second author, it's in review now, but it should qualify. We managed to get from 76% to 83% accuracy finally, just using microphone dataset. Paper published [here](https://arxiv.org/abs/2211.09376).
